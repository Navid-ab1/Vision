{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import cv2\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from regressor import CNNModel\n",
    "from loader import resize\n",
    "\n",
    "def load_model(model_path='model.pth'):\n",
    "    model = CNNModel()\n",
    "    model.load_state_dict(torch.load(model_path))\n",
    "    model.eval()\n",
    "    return model\n",
    "\n",
    "def preprocess_image(image, size=(224, 224)):\n",
    "    resized_image, _ = resize(image, np.zeros(8), size)\n",
    "    resized_image = torch.tensor(resized_image, dtype=torch.float32).permute(2, 0, 1) / 255.0\n",
    "    return resized_image.unsqueeze(0)\n",
    "\n",
    "def de_normalize_points(points, original_size, resized_size=(224, 224)):\n",
    "    original_width, original_height = original_size\n",
    "    resized_width, resized_height = resized_size\n",
    "\n",
    "    scale_x = original_width / resized_width\n",
    "    scale_y = original_height / resized_height\n",
    "\n",
    "    de_normalized_points = points.copy()\n",
    "    for i in range(4):\n",
    "        de_normalized_points[2*i] *= scale_x\n",
    "        de_normalized_points[2*i+1] *= scale_y\n",
    "\n",
    "    return de_normalized_points\n",
    "\n",
    "def corners(image: np.ndarray) -> np.ndarray:\n",
    "    model = load_model()\n",
    "    original_size = image.shape[1], image.shape[0]  # width, height\n",
    "\n",
    "    preprocessed_image = preprocess_image(image)\n",
    "    with torch.no_grad():\n",
    "        output_points = model(preprocessed_image).squeeze(0).numpy()\n",
    "\n",
    "    de_normalized_points = de_normalize_points(output_points, original_size)\n",
    "    return de_normalized_points\n",
    "\n",
    "def evaluate_model(data_dir, model_path='model.pth'):\n",
    "    from loader import load  # Ensure load function is correctly imported here\n",
    "    \n",
    "    images, true_points = load(data_dir)\n",
    "    model = load_model(model_path)\n",
    "\n",
    "    predicted_points = []\n",
    "    for image in images:\n",
    "        predicted_points.append(corners(image))\n",
    "\n",
    "    predicted_points = np.array(predicted_points)\n",
    "    true_points = np.array(true_points)\n",
    "\n",
    "    mse = mean_squared_error(true_points.reshape(-1), predicted_points.reshape(-1))\n",
    "    print(f\"Mean Squared Error: {mse:.4f}\")\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    image_path = 'path_to_some_image.jpg'  # Replace with an actual image path for testing\n",
    "    image = cv2.imread(image_path)\n",
    "    if image is not None:\n",
    "        predicted_corners = corners(image)\n",
    "        print(f\"Predicted corners: {predicted_corners}\")\n",
    "    else:\n",
    "        print(\"Image not found or unable to load.\")\n",
    "    \n",
    "    data_dir = '/home/navid/Desktop/VisionProject/four-corners'\n",
    "    evaluate_model(data_dir)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
